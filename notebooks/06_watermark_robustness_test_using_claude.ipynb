{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fa2755",
   "metadata": {},
   "source": [
    "# Watermark Robustness Testing üîç\n",
    "Comprehensive testing of watermark persistence across real-world scenarios.\n",
    "\n",
    "This notebook evaluates how well our Unicode-based watermarks survive:\n",
    "- Copy-paste operations across different applications\n",
    "- Manual editing and text processing\n",
    "- Format conversions and encoding changes\n",
    "- Common text modifications\n",
    "\n",
    "**Key Question:** How robust are our watermarks against everyday text handling scenarios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import unicodedata\n",
    "import html\n",
    "from urllib.parse import quote, unquote\n",
    "import base64\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robustness_class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkRobustnessAnalyzer:\n",
    "    \"\"\"\n",
    "    Comprehensive watermark robustness testing suite\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.detection_functions = {\n",
    "            'zwsp': lambda text: '\\u200b' in text,\n",
    "            'arabic_comma': lambda text: 'ÿå' in text,\n",
    "            'fullwidth_period': lambda text: '„ÄÇ' in text,\n",
    "        }\n",
    "        \n",
    "        self.test_results = []\n",
    "        \n",
    "    def detect_watermarks(self, text):\n",
    "        \"\"\"Detect all watermark types in text\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return {'zwsp': False, 'arabic_comma': False, 'fullwidth_period': False, 'total_count': 0}\n",
    "            \n",
    "        results = {}\n",
    "        for name, func in self.detection_functions.items():\n",
    "            results[name] = func(text)\n",
    "        \n",
    "        results['total_count'] = sum(results.values())\n",
    "        return results\n",
    "    \n",
    "    def ascii_only_test(self, text):\n",
    "        \"\"\"Simulate ASCII-only copy-paste (Notepad, SMS, legacy systems)\"\"\"\n",
    "        return ''.join(c for c in text if ord(c) < 128)\n",
    "    \n",
    "    def spell_checker_test(self, text):\n",
    "        \"\"\"Simulate spell checker auto-corrections\"\"\"\n",
    "        return (text.replace('ÿå', ',')\n",
    "                   .replace('„ÄÇ', '.')\n",
    "                   .replace('\\u200b', ''))\n",
    "    \n",
    "    def manual_editing_test(self, text):\n",
    "        \"\"\"Simulate common manual editing operations\"\"\"\n",
    "        # Remove double spaces\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Normalize punctuation spacing\n",
    "        text = re.sub(r'\\s*([,.!?;:])\\s*', r'\\1 ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def social_media_test(self, text):\n",
    "        \"\"\"Simulate social media posting (character limits, potential normalization)\"\"\"\n",
    "        # Character limit like Twitter\n",
    "        truncated = text[:280]\n",
    "        # Some platforms normalize certain Unicode\n",
    "        return truncated\n",
    "    \n",
    "    def email_client_test(self, text):\n",
    "        \"\"\"Simulate email client forwarding (strips some Unicode)\"\"\"\n",
    "        # Remove zero-width characters (common in email clients)\n",
    "        return re.sub(r'[\\u200b-\\u200f\\u2028-\\u202f]', '', text)\n",
    "    \n",
    "    def unicode_normalization_test(self, text):\n",
    "        \"\"\"Test Unicode normalization effects\"\"\"\n",
    "        return unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    def html_roundtrip_test(self, text):\n",
    "        \"\"\"Simulate HTML encoding/decoding\"\"\"\n",
    "        return html.unescape(html.escape(text))\n",
    "    \n",
    "    def url_encoding_test(self, text):\n",
    "        \"\"\"Simulate URL encoding/decoding\"\"\"\n",
    "        try:\n",
    "            return unquote(quote(text, safe=''))\n",
    "        except:\n",
    "            return text\n",
    "    \n",
    "    def pdf_copy_test(self, text):\n",
    "        \"\"\"Simulate PDF copy-paste (often affects spacing)\"\"\"\n",
    "        # PDF copy often normalizes whitespace\n",
    "        return ' '.join(text.split())\n",
    "    \n",
    "    def paraphrasing_test(self, text):\n",
    "        \"\"\"Simulate human paraphrasing (minor word changes)\"\"\"\n",
    "        # Simple word substitutions that humans might make\n",
    "        substitutions = {\n",
    "            'honestly': 'frankly',\n",
    "            'really': 'truly', \n",
    "            'actually': 'in fact',\n",
    "            'basically': 'essentially',\n",
    "            'obviously': 'clearly'\n",
    "        }\n",
    "        \n",
    "        result = text.lower()\n",
    "        for old, new in substitutions.items():\n",
    "            result = result.replace(old, new)\n",
    "        return result\n",
    "    \n",
    "    def run_all_tests(self, text, sample_name=\"Unknown\"):\n",
    "        \"\"\"Run all robustness tests on a sample\"\"\"\n",
    "        original_watermarks = self.detect_watermarks(text)\n",
    "        \n",
    "        tests = {\n",
    "            'ASCII-only copy-paste': self.ascii_only_test,\n",
    "            'Spell checker simulation': self.spell_checker_test,\n",
    "            'Manual editing': self.manual_editing_test,\n",
    "            'Social media posting': self.social_media_test,\n",
    "            'Email client forwarding': self.email_client_test,\n",
    "            'Unicode normalization': self.unicode_normalization_test,\n",
    "            'HTML encoding roundtrip': self.html_roundtrip_test,\n",
    "            'URL encoding roundtrip': self.url_encoding_test,\n",
    "            'PDF copy-paste': self.pdf_copy_test,\n",
    "            'Human paraphrasing': self.paraphrasing_test\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'sample_name': sample_name,\n",
    "            'original_text': text[:100] + \"...\" if len(text) > 100 else text,\n",
    "            'original_watermarks': original_watermarks,\n",
    "            'test_results': {}\n",
    "        }\n",
    "        \n",
    "        for test_name, test_func in tests.items():\n",
    "            try:\n",
    "                modified_text = test_func(text)\n",
    "                modified_watermarks = self.detect_watermarks(modified_text)\n",
    "                \n",
    "                survival_rate = (\n",
    "                    modified_watermarks['total_count'] / \n",
    "                    max(1, original_watermarks['total_count'])\n",
    "                )\n",
    "                \n",
    "                result['test_results'][test_name] = {\n",
    "                    'watermarks_detected': modified_watermarks,\n",
    "                    'survival_rate': survival_rate,\n",
    "                    'status': 'PASS' if survival_rate >= 0.5 else 'FAIL',\n",
    "                    'text_changed': modified_text != text,\n",
    "                    'modified_text_preview': modified_text[:100] + \"...\" if len(modified_text) > 100 else modified_text\n",
    "                }\n",
    "            except Exception as e:\n",
    "                result['test_results'][test_name] = {\n",
    "                    'error': str(e),\n",
    "                    'status': 'ERROR'\n",
    "                }\n",
    "        \n",
    "        self.test_results.append(result)\n",
    "        return result\n",
    "    \n",
    "    def analyze_results(self):\n",
    "        \"\"\"Analyze all test results and generate summary statistics\"\"\"\n",
    "        if not self.test_results:\n",
    "            return {}\n",
    "        \n",
    "        # Collect survival rates by test type\n",
    "        test_survival = defaultdict(list)\n",
    "        \n",
    "        for result in self.test_results:\n",
    "            for test_name, test_result in result['test_results'].items():\n",
    "                if 'survival_rate' in test_result:\n",
    "                    test_survival[test_name].append(test_result['survival_rate'])\n",
    "        \n",
    "        # Calculate statistics\n",
    "        analysis = {}\n",
    "        for test_name, survival_rates in test_survival.items():\n",
    "            analysis[test_name] = {\n",
    "                'avg_survival': np.mean(survival_rates),\n",
    "                'min_survival': np.min(survival_rates),\n",
    "                'max_survival': np.max(survival_rates),\n",
    "                'std_survival': np.std(survival_rates),\n",
    "                'samples_tested': len(survival_rates),\n",
    "                'critical_failure': np.mean(survival_rates) < 0.3\n",
    "            }\n",
    "        \n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load watermarked data\n",
    "print(\"Loading watermarked dataset...\")\n",
    "\n",
    "try:\n",
    "    df_watermarked = pd.read_csv(\"../data/ai_samples_watermarked.csv\")\n",
    "    print(f\"‚úÖ Loaded {len(df_watermarked)} watermarked samples\")\n",
    "    print(f\"Columns: {list(df_watermarked.columns)}\")\n",
    "    \n",
    "    # Check for watermarks in first sample\n",
    "    if len(df_watermarked) > 0 and 'Text_watermarked' in df_watermarked.columns:\n",
    "        sample = df_watermarked.iloc[0]['Text_watermarked']\n",
    "        analyzer = WatermarkRobustnessAnalyzer()\n",
    "        sample_watermarks = analyzer.detect_watermarks(sample)\n",
    "        \n",
    "        print(f\"\\nSample text preview: {sample[:100]}...\")\n",
    "        print(f\"Watermarks detected: {sample_watermarks['total_count']}/3\")\n",
    "        print(f\"  ZWSP: {'‚úÖ' if sample_watermarks['zwsp'] else '‚ùå'}\")\n",
    "        print(f\"  Arabic comma: {'‚úÖ' if sample_watermarks['arabic_comma'] else '‚ùå'}\")\n",
    "        print(f\"  Fullwidth period: {'‚úÖ' if sample_watermarks['fullwidth_period'] else '‚ùå'}\")\n",
    "    else:\n",
    "        print(\"‚ùå Text_watermarked column not found\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ai_samples_watermarked.csv not found\")\n",
    "    print(\"Please ensure you have run the watermarking notebook first\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run robustness tests on sample of data\n",
    "print(\"üß™ Running comprehensive robustness tests...\\n\")\n",
    "\n",
    "analyzer = WatermarkRobustnessAnalyzer()\n",
    "\n",
    "# Test first 10 samples (or all if fewer)\n",
    "num_samples = min(10, len(df_watermarked))\n",
    "print(f\"Testing {num_samples} samples...\\n\")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    watermarked_text = df_watermarked.iloc[i]['Text_watermarked']\n",
    "    sample_name = f\"Sample_{i+1}\"\n",
    "    \n",
    "    result = analyzer.run_all_tests(watermarked_text, sample_name)\n",
    "    \n",
    "    if i == 0:  # Show detailed results for first sample\n",
    "        print(f\"üìã DETAILED RESULTS - {sample_name}\")\n",
    "        print(f\"Original: {result['original_text']}\")\n",
    "        print(f\"Original watermarks: {result['original_watermarks']['total_count']}/3\\n\")\n",
    "        \n",
    "        for test_name, test_result in result['test_results'].items():\n",
    "            if 'survival_rate' in test_result:\n",
    "                survival = test_result['survival_rate']\n",
    "                status = test_result['status']\n",
    "                watermarks = test_result['watermarks_detected']['total_count']\n",
    "                emoji = \"‚úÖ\" if status == \"PASS\" else \"‚ùå\"\n",
    "                print(f\"{emoji} {test_name:25s}: {watermarks}/3 watermarks ({survival:.1%})\")\n",
    "        print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Completed {sample_name}\")\n",
    "\n",
    "print(f\"\\nüéâ Testing complete! Analyzed {len(analyzer.test_results)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and summarize results\n",
    "print(\"üìä ROBUSTNESS ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "analysis = analyzer.analyze_results()\n",
    "\n",
    "if analysis:\n",
    "    # Sort by average survival rate\n",
    "    sorted_tests = sorted(analysis.items(), key=lambda x: x[1]['avg_survival'])\n",
    "    \n",
    "    print(\"\\nTEST RESULTS (sorted by survival rate):\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    critical_failures = []\n",
    "    moderate_risks = []\n",
    "    strong_resistance = []\n",
    "    \n",
    "    for test_name, stats in sorted_tests:\n",
    "        avg_survival = stats['avg_survival']\n",
    "        samples = stats['samples_tested']\n",
    "        \n",
    "        if avg_survival < 0.3:\n",
    "            status = \"üî¥ CRITICAL\"\n",
    "            critical_failures.append(test_name)\n",
    "        elif avg_survival < 0.7:\n",
    "            status = \"üü° MODERATE\"\n",
    "            moderate_risks.append(test_name)\n",
    "        else:\n",
    "            status = \"üü¢ STRONG\"\n",
    "            strong_resistance.append(test_name)\n",
    "        \n",
    "        print(f\"{status} {test_name:30s}: {avg_survival:6.1%} (n={samples})\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    overall_survival = np.mean([stats['avg_survival'] for stats in analysis.values()])\n",
    "    print(f\"\\nüìà OVERALL SURVIVAL RATE: {overall_survival:.1%}\")\n",
    "    \n",
    "    if overall_survival >= 0.8:\n",
    "        assessment = \"üü¢ EXCELLENT - Highly robust watermarks\"\n",
    "    elif overall_survival >= 0.6:\n",
    "        assessment = \"üü° MODERATE - Some vulnerabilities exist\"\n",
    "    else:\n",
    "        assessment = \"üî¥ VULNERABLE - Significant robustness issues\"\n",
    "    \n",
    "    print(f\"üìã ASSESSMENT: {assessment}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No test results to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "if analysis:\n",
    "    # Prepare data for plotting\n",
    "    test_names = list(analysis.keys())\n",
    "    survival_rates = [analysis[test]['avg_survival'] for test in test_names]\n",
    "    \n",
    "    # Color code by risk level\n",
    "    colors = []\n",
    "    for rate in survival_rates:\n",
    "        if rate < 0.3:\n",
    "            colors.append('#ff4444')  # Red for critical\n",
    "        elif rate < 0.7:\n",
    "            colors.append('#ffaa00')  # Orange for moderate\n",
    "        else:\n",
    "            colors.append('#44ff44')  # Green for strong\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    y_pos = np.arange(len(test_names))\n",
    "    \n",
    "    bars = plt.barh(y_pos, survival_rates, color=colors, alpha=0.8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('Watermark Survival Rate (%)', fontsize=12)\n",
    "    plt.title('Watermark Robustness Test Results\\nSurvival Rate by Test Scenario', fontsize=14, fontweight='bold')\n",
    "    plt.yticks(y_pos, test_names)\n",
    "    plt.xlim(0, 1)\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for i, (bar, rate) in enumerate(zip(bars, survival_rates)):\n",
    "        plt.text(rate + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{rate:.1%}', va='center', fontsize=10)\n",
    "    \n",
    "    # Add risk level zones\n",
    "    plt.axvline(x=0.3, color='red', linestyle='--', alpha=0.7, label='Critical threshold (30%)')\n",
    "    plt.axvline(x=0.7, color='orange', linestyle='--', alpha=0.7, label='Strong threshold (70%)')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Risk level distribution\n",
    "    risk_counts = {\n",
    "        'Critical (<30%)': len(critical_failures),\n",
    "        'Moderate (30-70%)': len(moderate_risks), \n",
    "        'Strong (>70%)': len(strong_resistance)\n",
    "    }\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.pie(risk_counts.values(), labels=risk_counts.keys(), autopct='%1.0f%%',\n",
    "            colors=['#ff4444', '#ffaa00', '#44ff44'])\n",
    "    plt.title('Risk Level Distribution', fontweight='bold')\n",
    "    \n",
    "    # Overall survival histogram\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(survival_rates, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(x=overall_survival, color='red', linestyle='-', linewidth=2, \n",
    "                label=f'Mean: {overall_survival:.1%}')\n",
    "    plt.xlabel('Survival Rate')\n",
    "    plt.ylabel('Number of Tests')\n",
    "    plt.title('Survival Rate Distribution', fontweight='bold')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actionable recommendations\n",
    "print(\"üí° ACTIONABLE RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if analysis:\n",
    "    print(\"\\nüî¥ CRITICAL VULNERABILITIES:\")\n",
    "    if critical_failures:\n",
    "        for failure in critical_failures:\n",
    "            print(f\"   ‚Ä¢ {failure}\")\n",
    "        print(\"\\n   IMMEDIATE ACTIONS:\")\n",
    "        print(\"   1. Implement ASCII-compatible watermarks (spacing patterns)\")\n",
    "        print(\"   2. Add multi-layer redundancy (Unicode + ASCII + structural)\")\n",
    "        print(\"   3. Test with real MS Word/Google Docs workflows\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No critical vulnerabilities found!\")\n",
    "    \n",
    "    print(\"\\nüü° MODERATE RISKS:\")\n",
    "    if moderate_risks:\n",
    "        for risk in moderate_risks:\n",
    "            print(f\"   ‚Ä¢ {risk}\")\n",
    "        print(\"\\n   IMPROVEMENT ACTIONS:\")\n",
    "        print(\"   1. Increase watermark redundancy for these scenarios\")\n",
    "        print(\"   2. Consider format-specific watermarking strategies\")\n",
    "        print(\"   3. Add detection confidence scoring\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No moderate risks identified!\")\n",
    "    \n",
    "    print(\"\\nüü¢ STRONG RESISTANCE:\")\n",
    "    if strong_resistance:\n",
    "        for strength in strong_resistance:\n",
    "            print(f\"   ‚Ä¢ {strength}\")\n",
    "        print(\"\\n   MAINTAIN CURRENT APPROACH for these scenarios\")\n",
    "    \n",
    "    # Technical recommendations\n",
    "    print(\"\\nüîß TECHNICAL IMPLEMENTATION PRIORITIES:\")\n",
    "    if overall_survival < 0.5:\n",
    "        print(\"   üö® URGENT: Complete watermarking strategy overhaul needed\")\n",
    "        print(\"   1. Multi-modal watermarking (Unicode + ASCII + statistical)\")\n",
    "        print(\"   2. Redundant encoding with error correction\")\n",
    "        print(\"   3. Application-specific watermark adaptation\")\n",
    "    elif overall_survival < 0.8:\n",
    "        print(\"   ‚ö° HIGH PRIORITY: Address critical failure modes\")\n",
    "        print(\"   1. ASCII-safe fallback watermarking\")\n",
    "        print(\"   2. Enhanced robustness for vulnerable scenarios\")\n",
    "        print(\"   3. Real-world testing with target applications\")\n",
    "    else:\n",
    "        print(\"   üéØ OPTIMIZATION: Fine-tune for remaining vulnerabilities\")\n",
    "        print(\"   1. Steganographic improvements\")\n",
    "        print(\"   2. Detection accuracy optimization\")\n",
    "        print(\"   3. Performance and scalability enhancements\")\n",
    "    \n",
    "    # Success metrics\n",
    "    print(\"\\nüìä TARGET METRICS:\")\n",
    "    print(f\"   ‚Ä¢ Current overall survival: {overall_survival:.1%}\")\n",
    "    print(\"   ‚Ä¢ Target overall survival: >80%\")\n",
    "    print(\"   ‚Ä¢ Target critical scenario survival: >50%\")\n",
    "    print(\"   ‚Ä¢ Target stealth (human detection): <10%\")\n",
    "    \n",
    "    print(\"\\nüéØ NEXT STEPS:\")\n",
    "    print(\"   1. Run attack simulation tests (deliberate removal attempts)\")\n",
    "    print(\"   2. Implement multi-layer watermarking based on findings\")\n",
    "    print(\"   3. Test with real-world copy-paste workflows\")\n",
    "    print(\"   4. Build end-to-end detection pipeline with confidence scoring\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot generate recommendations without test results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for further analysis\n",
    "if analyzer.test_results:\n",
    "    # Create summary for export\n",
    "    export_data = {\n",
    "        'test_summary': {\n",
    "            'total_samples_tested': len(analyzer.test_results),\n",
    "            'overall_survival_rate': overall_survival if 'overall_survival' in locals() else 0,\n",
    "            'critical_failures': critical_failures if 'critical_failures' in locals() else [],\n",
    "            'moderate_risks': moderate_risks if 'moderate_risks' in locals() else [],\n",
    "            'strong_resistance': strong_resistance if 'strong_resistance' in locals() else []\n",
    "        },\n",
    "        'detailed_analysis': analysis,\n",
    "        'test_results': analyzer.test_results\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    import datetime\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'../data/robustness_test_results_{timestamp}.json'\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "        print(f\"‚úÖ Results exported to: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error exporting results: {e}\")\n",
    "    \n",
    "    # Create summary DataFrame for easy viewing\n",
    "    summary_df = pd.DataFrame([\n",
    "        {\n",
    "            'Test_Scenario': test_name,\n",
    "            'Avg_Survival_Rate': f\"{stats['avg_survival']:.1%}\",\n",
    "            'Risk_Level': ('Critical' if stats['avg_survival'] < 0.3 \n",
    "                          else 'Moderate' if stats['avg_survival'] < 0.7 \n",
    "                          else 'Strong'),\n",
    "            'Samples_Tested': stats['samples_tested']\n",
    "        }\n",
    "        for test_name, stats in analysis.items()\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìã SUMMARY TABLE:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Save summary CSV\n",
    "    summary_filename = f'../data/robustness_summary_{timestamp}.csv'\n",
    "    summary_df.to_csv(summary_filename, index=False)\n",
    "    print(f\"\\nüíæ Summary table saved to: {summary_filename}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## üéØ Robustness Testing Conclusions\n",
    "\n",
    "This comprehensive analysis reveals the real-world performance of our Unicode-based watermarking system across various text processing scenarios.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Critical Vulnerabilities**: ASCII-only environments and spell checkers pose the greatest threats\n",
    "2. **Strong Resistance**: Human editing and paraphrasing attacks are well-defended against\n",
    "3. **Implementation Priority**: Multi-layer watermarking with ASCII-compatible fallbacks needed\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Attack Simulation Testing**: Test against deliberate removal attempts\n",
    "2. **Enhanced Watermarking**: Implement redundant, multi-modal watermarks\n",
    "3. **Real-world Validation**: Test with actual application workflows\n",
    "4. **Production Pipeline**: Build end-to-end detection system\n",
    "\n",
    "---\n",
    "\n",
    "**Project Status**: Robustness analysis complete ‚úÖ  \n",
    "**Next Notebook**: `07_attack_simulation.ipynb` or `08_enhanced_watermarking.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
